{
    "results_output_path": "/nvme/gc/interactive-eval/InteractiveEval/dev/results/reasoning_test_result.json",
    "steps": [
        {
            "step_type": "simple_multiple_choice",
            "step_name": "Reclor",
            "save_dataset": true,
            "dataset_config": {
                "type": "reclor",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "validation",
                    "name_or_path": "/nvme/gc/interactive-eval/InteractiveEval/dev/datasets/reclor",
                    "fewshot_split": "train",
                    "fewshot_num": 5,
                    "tokenizer_name_or_path": "/nvme/shared_ckpt/llama2-7b-chat-hf",
                    "multiple_choice_template_name": "reasoning",
                    "system_prompt": "You are a helpful assistant that answers problems correctly. You strictly follow the output format by outputing only the answer key without any explanation.\n"
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "/nvme/gc/interactive-eval/InteractiveEval/dev/outputs",
                "inference_kwargs": {
                    "model_name": "llama2-7b-chat-hf",
                    "base_url": [""],
                    "timeout": 60,
                    "num_workers": 4,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": ["A", "B", "C", "D"],
                        "max_new_tokens": 20
                    }
                }
            },
            "eval_config": {
            }
        },
        {
            "step_type": "interactive_evaluation",
            "step_name": "Interactive evaluation with MCP results",
            "output_path": "/nvme/gc/interactive-eval/InteractiveEval/dev/outputs",
            "max_rounds": 5,
            "max_instances": 200,
            "prompter_config": {
                "mcp_prompt": "default",
                "interactor": {
                    "system_prompt": "default",
                    "init_user_prompt": "default"
                },
                "candidate": {
                    "system_prompt": "default"
                },
                "evaluator": {
                    "system_prompt": "clear",
                    "user_prompt": "add_detailed_criteria",
                    "init_user_prompt": "add_detailed_criteria",
                    "fewshot_prompt": "clear",
                    "system_prompt_json_example": "clear"
                }
            },
            "roles_config": {
                "candidate": {
                    "type": "remote_hf",
                    "inference_kwargs": {
                        "model_name": "llama2-7b-chat-hf",
                        "base_url": ["your-tgi-url"],
                        "timeout": 600,
                        "num_workers": 4,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true,
                        "generation_config": {
                            "max_new_tokens": 400
                        }
                    },
                    "prompt_postprocessor_config": {
                        "tokenizer_name_or_path": "/nvme/shared_ckpt/llama2-7b-chat-hf"
                    }
                },
                "interactor" : {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your-openai-key",
                        "openai_proxy": "",
                        "openai_timeout": 300.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                },
                "evaluator": {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your-openai-key",
                        "openai_proxy": "",
                        "openai_timeout": 300.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                }
            }

        }
    ]
}