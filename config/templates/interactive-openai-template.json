{
    "results_output_path": "/hdd1/yzh/InteractiveEval/results/llama2-70b-test.json",
    "steps": [
        {
            "step_type": "simple_multiple_choice",
            "step_name": "ARC Challenge MCP",
            "save_dataset": true,
            "dataset_config": {
                "type": "arc_challenge",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "test",
                    "name_or_path": "/hdd1/yzh/datasets/ai2_arc",
                    "config_name": "ARC-Challenge",
                    "fewshot_split": "train",
                    "fewshot_num": 25,
                    "multiple_choice_template_name": "test_1"
                },
                "augment_dataset_kwargs": {
                    "num_instances": 4,
                    "num_keeps": 1
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "/hdd1/yzh/InteractiveEval/outputs",
                "inference_kwargs": {
                    "model_name": "llama2-70b-test",
                    "base_url": ["your-tgi-url"],
                    "timeout": 60,
                    "num_workers": 8,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": ["A", "B", "C", "D", "E"],
                        "max_new_tokens": 20
                    }"your-tgi-url"
                }
            },
            "eval_config": {
                "aggregate_mode": "mean"
            }
        },
        {
            "step_type": "interactive_evaluation",
            "step_name": "Interactive evaluation with MCP results",
            "output_path": "/hdd1/yzh/InteractiveEval/outputs",
            "validated_problems_path": "assets/validated_problems_gpt-4-1106-preview.json",
            "max_rounds": 5,
            "max_instances": 200,
            "prompter_config": {
                "mcp_prompt": "default",
                "interactor": {
                    "system_prompt": "default",
                    "init_user_prompt": "default"
                },
                "candidate": {
                    "system_prompt": "default"
                },
                "evaluator": {
                    "system_prompt": "clear",
                    "user_prompt": "add_detailed_criteria",
                    "init_user_prompt": "add_detailed_criteria",
                    "fewshot_prompt": "clear",
                    "system_prompt_json_example": "clear"
                }
            },
            "roles_config": {
                "candidate": {
                    "type": "remote_hf",
                    "inference_kwargs": {
                        "model_name": "llama2-70b-test",
                        "base_url": ["your-tgi-url"],
                        "timeout": 60,
                        "num_workers": 8,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true,
                        "generation_config": {
                            "max_new_tokens": 400
                        }
                    },
                    "prompt_postprocessor_config": {
                        "tokenizer_name_or_path": "/hdd1/yzh/ckpts/llama-2-70b-chat-hf"
                    }
                },
                "interactor" : {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your-openai-key",
                        "openai_api_base": "your-openai-api-base",
                        "openai_proxy": "",
                        "openai_timeout": 120.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                },
                "evaluator": {
                    "type": "openai",
                    "inference_kwargs": {
                        "openai_model": "gpt-4-1106-preview",
                        "openai_key": "your-openai-key",
                        "openai_api_base": "your-openai-api-base",
                        "openai_proxy": "",
                        "openai_timeout": 120.0,
                        "generation_config": {
                            "max_tokens": 400,
                            "n": 1,
                            "temperature": 0.0,
                            "seed": 0
                        },
                        "num_workers": 16,
                        "request_limit": 100000,
                        "request_limit_period": 60,
                        "dump_individual_rsp": true
                    }
                }
            }

        },
        {
            "step_type": "simple_multiple_choice",
            "step_name": "ARC Challenge MCP",
            "save_dataset": true,
            "dataset_config": {
                "type": "arc_challenge",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "test",
                    "name_or_path": "/hdd1/yzh/datasets/ai2_arc",
                    "config_name": "ARC-Challenge",
                    "fewshot_split": "train",
                    "fewshot_num": 25,
                    "multiple_choice_template_name": "test_1"
                },
                "augment_dataset_kwargs": {
                    "num_instances": 4,
                    "num_keeps": 1
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "/hdd1/yzh/InteractiveEval/outputs",
                "inference_kwargs": {
                    "model_name": "llama2-70b-test",
                    "base_url": ["your-tgi-url"],
                    "timeout": 60,
                    "num_workers": 8,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": ["A", "B", "C", "D", "E"],
                        "max_new_tokens": 20
                    }
                }
            },
            "eval_config": {
                "aggregate_mode": "strict"
            }
        },
        {
            "step_type": "simple_multiple_choice",
            "step_name": "ARC Challenge MCP",
            "save_dataset": true,
            "dataset_config": {
                "type": "arc_challenge",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "test",
                    "name_or_path": "/hdd1/yzh/datasets/ai2_arc",
                    "config_name": "ARC-Challenge",
                    "fewshot_split": "train",
                    "fewshot_num": 25,
                    "multiple_choice_template_name": "test_1"
                },
                "augment_dataset_kwargs": {
                    "num_instances": 4,
                    "num_keeps": 1
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "/hdd1/yzh/InteractiveEval/outputs",
                "inference_kwargs": {
                    "model_name": "llama2-70b-test",
                    "base_url": ["your-tgi-url"],
                    "timeout": 60,
                    "num_workers": 8,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": ["A", "B", "C", "D", "E"],
                        "max_new_tokens": 20
                    }
                }
            },
            "eval_config": {
                "aggregate_mode": "vote",
                "vote_threshold": 0.5
            }
        },
        {
            "step_type": "simple_multiple_choice",
            "step_name": "ARC Challenge MCP",
            "save_dataset": true,
            "dataset_config": {
                "type": "arc_challenge",
                "dataset_kwargs": {
                    "seed": 2,
                    "split": "test",
                    "name_or_path": "/hdd1/yzh/datasets/ai2_arc",
                    "config_name": "ARC-Challenge",
                    "fewshot_split": "train",
                    "fewshot_num": 25,
                    "multiple_choice_template_name": "test_1"
                },
                "augment_dataset_kwargs": {
                    "num_instances": 4,
                    "num_keeps": 1
                }
            },
            "inference_config": {
                "type": "remote_hf",
                "output_path": "/hdd1/yzh/InteractiveEval/outputs",
                "inference_kwargs": {
                    "model_name": "llama2-70b-test",
                    "base_url": ["your-tgi-url"],
                    "timeout": 60,
                    "num_workers": 4,
                    "request_limit": 100000,
                    "request_limit_period": 60,
                    "dump_individual_rsp": true,
                    "generation_config": {
                        "stop_sequences": ["A", "B", "C", "D", "E"],
                        "max_new_tokens": 20
                    }
                }
            },
            "eval_config": {
                "aggregate_mode": "ignore_augmented"
            }
        }
    ]
}